{{- include "radar-jdbc-connector.validateValues" . }}
{{ $name := ternary  .Values.sink.name .Values.source.name (eq .Values.mode "sink") }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "radar-jdbc-connector.fullname" . }}
  labels:
    {{- include "radar-jdbc-connector.labels" . | nindent 4 }}
data:
  connector.properties: |
    # Kafka connector configuration
    name = {{ $name }}

    tasks.max = {{ .Values.maxTasks }}

    # General connection parameters
    connection.url={{ .Values.jdbc.url }}
    connection.user={{ .Values.jdbc.user }}
    connection.password={{ .Values.jdbc.password }}
    dialect.name = {{ .Values.jdbc.dialect }}
    max.retries = 15
    # Wait 10 minutes before retrying failed task
    retry.backoff.ms = 600000
    connection.attempts = 15
    # Wait 10 minutes before attempting connection
    connection.backoff.ms = 600000

    {{- if eq .Values.mode "sink" }}
    # Kafka connector configuration
    connector.class = io.confluent.connect.jdbc.JdbcSinkConnector

    {{- with .Values.sink }}
    insert.mode = {{ .insertMode }}
    # Topics that will be consumed
    topics = {{ .topics }}
    table.name.format = {{ .tableNameFormat }}
    auto.create = {{ .autoCreate }}
    {{- with .primaryKeys }}
    pk.mode = {{ .mode }}
    pk.fields = {{ join ", " .fields }}
    {{- end }}

    {{- end }}
    transforms=mergeKey,timestamp
    transforms.mergeKey.type=org.radarbase.kafka.connect.transforms.MergeKey
    transforms.timestamp.type=org.radarbase.kafka.connect.transforms.TimestampConverter
    transforms.timestamp.fields=time,timeReceived,timeCompleted,timestamp
    {{- end }}

    {{- if eq .Values.mode "source" }}
    # Kafka connector configuration
    connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
    {{- with .Values.source }}
    {{- if .schema }}
    schema.pattern = {{ .schema }}
    {{- end }}
    table.whitelist = {{ .tableWhitelist }}
    topic.prefix = {{ .topicPrefix }}
    mode = {{ .mode }}
    incrementing.column.name = {{ .incrementingColumnName }}
    {{- if .keyField }}
    transforms=createKey,extractField
    transforms.createKey.type = org.apache.kafka.connect.transforms.ValueToKey
    transforms.createKey.fields = {{ .keyField }}
    transforms.extractField.type = org.apache.kafka.connect.transforms.ExtractField$Key
    transforms.extractField.field = {{ .keyField }}
    {{- end }}

    {{- end }}

    errors.log.enable = true
    errors.log.include.messages = true
    topic.creation.default.replication.factor = 2
    topic.creation.default.partitions = 3
    key.converter = io.confluent.connect.avro.AvroConverter
    key.converter.schema.registry.url = {{ .Values.schema_registry }}
    value.converter = io.confluent.connect.avro.AvroConverter
    value.converter.schema.registry.url = {{ .Values.schema_registry }}
    {{- end }}
  healthcheck.sh: |
    #!/bin/sh
    STATUS=$(curl -sf localhost:8083/connectors/{{ $name }}/status | grep -o '\"state\":\"[^\"]*\"')
    if echo "$STATUS" | tr '\\n' ',' | grep -q FAILED; then
      exit 1
    elif [ $(echo "$STATUS" | grep RUNNING | wc -l) -le 1 ]; then
      exit 1
    fi
