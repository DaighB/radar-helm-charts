# Default values for radar-jdbc-connector.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# -- Number of radar-fitbit-connector replicas to deploy
replicaCount: 1

image:
  # -- radar-jdbc-connector image repository
  repository: radarbase/radar-jdbc-connector
  # -- radar-jdbc-connector image tag (immutable tags are recommended)
  # Overrides the image tag whose default is the chart appVersion.
  tag: dev
  # -- radar-jdbc-connector image pull policy
  pullPolicy: IfNotPresent

# -- Docker registry secret names as an array
imagePullSecrets: []

# -- String to partially override radar-jdbc-connector.fullname template with a string (will prepend the release name)
nameOverride: ""
# -- String to fully override radar-jdbc-connector.fullname template with a string
fullnameOverride: ""

# -- Configure radar-jdbc-connector pods' Security Context
podSecurityContext: {}
  # fsGroup: 2000

# -- Configure radar-jdbc-connector containers' Security Context
securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  # -- Kubernetes Service type
  type: ClusterIP
  # -- radar-jdbc-connector port
  port: 8083

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi

  # -- CPU/Memory resource requests
  requests:
    cpu: 100m
    memory: 1Gi

# -- Node labels for pod assignment
nodeSelector: {}

# -- Toleration labels for pod assignment
tolerations: []

# -- Affinity labels for pod assignment
affinity: {}

# -- URI of Kafka brokers of the cluster
kafka: PLAINTEXT://cp-kafka-headless:9092
# -- Number of Kafka brokers. This is used to validate the cluster availability at connector init.
kafka_num_brokers: "3"
# -- URL of the Kafka schema registry
schema_registry: http://cp-schema-registry:8081

maxTasks: 2

# -- Either source or sink
mode: sink

source:
  # -- Name of the connector Kafka producer group
  name: radar-jdbc-source
  # -- Comma-separted list of tables to read
  tableWhitelist: ""
  # -- Prefix to prepend to table names to generate the name of the Kafka topic to publish data to.
  topicPrefix: ""
  # -- How to detect new values
  mode: incrementing
  # -- When using mode incrementing, which colum to use as incrementing. If empty, autodetection will be used.
  incrementingColumnName: ""

sink:
  # -- Name of the connector Kafka consumer group
  name: radar-jdbc-sink
  # -- create table if it does not exist
  autoCreate: true
  # -- How to insert new values into the database
  insertMode: upsert
  primaryKeys:
    #-- where to read the primary keys from when creating the table
    mode: record_value
    #-- fields to include as primary keys when creating the table
    fields:
      - time
      - userId
      - projectId
  # -- Comma-separated list of topics the connector will read from and ingest into the database
  topics: android_phone_relative_location, android_phone_battery_level, connect_upload_altoida_summary, connect_fitbit_intraday_heart_rate, connect_fitbit_intraday_steps
  tableNameFormat: "${topic}"

# -- Additional environment variables to pass to the connector. These can be used to pass supported kafka and connect specifc [configs](https://docs.confluent.io/platform/current/installation/docker/config-reference.html#kconnect-long-configuration)
environment:
  # -- Protocol used to communicate with brokers. Valid values are: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL.
  CONNECT_SECURITY_PROTOCOL: PLAINTEXT

jdbc:
  # -- Host of the TimescaleDB database
  url: jdbc:postgresql://timescaledb-postgresql-headless:5432/grafana-metrics
  # -- TimescaleDB database username
  user: grafana
  # -- TimescaleDB database password
  password: password
  dialect: TimescaleDBDatabaseDialect
