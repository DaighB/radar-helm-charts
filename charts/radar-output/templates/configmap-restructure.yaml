apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "radar-output.fullname" . }}-restructure
  labels:
    app: {{ template "radar-output.name" . }}
    chart: {{ template "radar-output.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  restructure.yml: |
    service:
      # Whether to run the application as a polling service.
      enable: true
      # Polling interval in seconds.
      interval: 300

    source:
      type: "{{ .Values.source.type }}"
      # Minio S3 settings
      s3:
        endpoint: "{{ .Values.source.s3.endpoint }}"
        accessToken: "{{ .Values.source.s3.accessToken }}"
        secretKey: "{{ .Values.source.s3.secretKey }}"
        bucket: "{{ .Values.source.s3.bucket }}"
        connectTimeout: {{ .Values.source.s3.connectTimeout }}
        writeTimeout: {{ .Values.source.s3.writeTimeout }}
        readTimeout: {{ .Values.source.s3.readTimeout }}
      azure:
        endpoint: "{{ .Values.source.azure.endpoint }}"
        username: "{{ .Values.source.azure.username }}"
        password: "{{ .Values.source.azure.password }}"
        accountName: "{{ .Values.source.azure.accountName }}"
        accountKey: "{{ .Values.source.azure.accountKey }}"
        sasToken: "{{ .Values.source.azure.sasToken }}"
        container: "{{ .Values.source.azure.container }}"
        connectTimeout: {{ .Values.source.azure.connectTimeout }}
        responseTimeout: {{ .Values.source.azure.responseTimeout }}
        writeTimeout: {{ .Values.source.azure.writeTimeout }}
        readTimeout: {{ .Values.source.azure.readTimeout }}

    target:
      type: "{{ .Values.target.type }}"
      s3:
        endpoint: "{{ .Values.target.s3.endpoint }}"
        accessToken: "{{ .Values.target.s3.accessToken }}"
        secretKey: "{{ .Values.target.s3.secretKey }}"
        bucket: "{{ .Values.target.s3.bucket }}"
        connectTimeout: {{ .Values.target.s3.connectTimeout }}
        writeTimeout: {{ .Values.target.s3.writeTimeout }}
        readTimeout: {{ .Values.target.s3.readTimeout }}
      azure:
        endpoint: "{{ .Values.target.azure.endpoint }}"
        username: "{{ .Values.target.azure.username }}"
        password: "{{ .Values.target.azure.password }}"
        accountName: "{{ .Values.target.azure.accountName }}"
        accountKey: "{{ .Values.target.azure.accountKey }}"
        sasToken: "{{ .Values.target.azure.sasToken }}"
        container: "{{ .Values.target.azure.container }}"
        connectTimeout: {{ .Values.target.azure.connectTimeout }}
        responseTimeout: {{ .Values.target.azure.responseTimeout }}
        writeTimeout: {{ .Values.target.azure.writeTimeout }}
        readTimeout: {{ .Values.target.azure.readTimeout }}

    redis:
      uri: "{{ .Values.redis.uri }}"
      lockPrefix: radar-output/lock/

    # Compression characteristics
    compression:
      # Compression type: none, zip or gzip
      type: gzip
      # Compression Factory class
      # factory: org.radarbase.hdfs.data.CompressionFactory
      # Additional compression properties
      # properties: {}

    # File format
    format:
      # Format type: CSV or JSON
      type: csv
      # Whether to deduplicate the files in each topic by default
      deduplication:
        enable: true
        # Deduplicate considering only distinct fields sourceId and time.
        # This may incur data loss if multiple measurements are recorded
        # at exactly the same time. By default, all values are considered
        # when looking at distinct lines.
        distinctFields: [key.sourceId, value.time, value.timeReceived]
      # Format factory class
      # factory: org.radarbase.hdfs.data.FormatFactory
      # Additional format properties
      # properties: {}

    # Worker settings
    worker:
      # Maximum number of files and converters to keep open while processing
      cacheSize: {{ .Values.worker.cacheSize }}
      # Maximum number of offsets in cache.
      cacheOffsetsSize: {{ .Values.worker.cacheOffsetsSize }}
      # Number of threads to do processing with
      numThreads: "{{ .Values.worker.numThreads }}"
      # Maximum number of files to process in any given topic.
      # maxFilesPerTopic: null
      minimumFileAge: {{ .Values.worker.minimumFileAge }}

    cleaner:
      # Enable cleaning up old source files
      enable: {{ gt (int (toString (.Values.cleaner.age))) 0 }}
      # Interval in seconds to clean data
      interval: 1800  # 21 minutes
      # Number of days after which a source file is considered old
      age: {{ .Values.cleaner.age }}

    #storage:
      #factory: org.radarbase.hdfs.storage.LocalStorageDriver
      #properties:
      #  localUid: 0
      #  localGid: 0

    # Path settings
    paths:
      # Input directories in HDFS
      inputs:
        - "{{ .Values.paths.input }}"
      # Root temporary directory for local file processing.
      temp: /output/+tmp
      # Output directory
      output: "{{ .Values.paths.output }}"
      # Output path construction factory
      factory: {{ .Values.paths.factory }}
      # Additional properties
      properties:
        {{ .Values.paths.properties | toYaml | indent 8 | trim }}

    # Individual topic configuration
    {{- if .Values.topics }}
    topics:
      {{ .Values.topics | toYaml | indent 6 | trim }}
    {{- else }}
    topics: {}
    {{- end }}
